{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keratin.metrics import dice, dice_loss\n",
    "import numpy as np\n",
    "from keratin.networks import unet\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from os import makedirs\n",
    "from skimage.transform import AffineTransform, matrix_transform, warp\n",
    "from skimage.morphology import dilation, erosion\n",
    "from skimage.morphology import disk\n",
    "import pandas as pd\n",
    "from nipype.utils.filemanip import load_json, save_json\n",
    "#%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = unet(256,256,n_channels=2)\n",
    "    model.compile(optimizer=Adam(lr=10e-5), \n",
    "              loss=dice_loss, \n",
    "              metrics=[dice])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make256(images, hints = None):\n",
    "    \n",
    "    if not hints:\n",
    "        bigM = np.zeros((len(images), 256, 256, 1))\n",
    "    else:\n",
    "        bigM = np.zeros((len(images), 256, 256, 2))\n",
    "    \n",
    "    for i, im in enumerate(images):\n",
    "\n",
    "        data = plt.imread(im)\n",
    "        if len(data.shape) == 3:\n",
    "            do_mean = True\n",
    "            data = (data[:,:,0]/255).astype(np.float32)\n",
    "            if hints:\n",
    "                hint = plt.imread(hints[i]).astype(np.float32)\n",
    "            \n",
    "        else:\n",
    "            do_mean = False\n",
    "            #print(\"mean_data\", np.mean(data))\n",
    "            data = (data/np.max(data)).astype(np.float32)\n",
    "            #print(\"mean data\", np.mean(data))\n",
    "\n",
    "        if data.shape[0] > 256:\n",
    "            data = data[:256, :]\n",
    "        if data.shape[1] > 256:\n",
    "            data = data[:, :256]\n",
    "\n",
    "        data_pad = np.pad(data, (((256-data.shape[0])//2, ((256-data.shape[0]) + (data.shape[0]%2 >0))//2), \n",
    "                                 ((256-data.shape[1])//2, ((256-data.shape[1]) + (data.shape[1]%2 >0))//2)), \n",
    "                          \"constant\", constant_values = (0,0))\n",
    "        \n",
    "        if hints:\n",
    "            \n",
    "            if hint.shape[0] > 256:\n",
    "                hint = hint[:256, :]\n",
    "            if hint.shape[1] > 256:\n",
    "                hint = hint[:, :256]\n",
    "            \n",
    "            hint_pad = np.pad(hint, (((256-hint.shape[0])//2, ((256-hint.shape[0]) + (hint.shape[0]%2 >0))//2), \n",
    "                         ((256-hint.shape[1])//2, ((256-hint.shape[1]) + (hint.shape[1]%2 >0))//2)), \n",
    "                  \"constant\", constant_values = (0,0))\n",
    "\n",
    "        \n",
    "        if do_mean:\n",
    "            bigM[i,:,:,0] = (data_pad - np.mean(data_pad)) / np.std(data_pad)\n",
    "            if hints:\n",
    "                bigM[i,:,:,1] = (hint_pad - np.mean(hint_pad)) / np.std(hint_pad)\n",
    "            \n",
    "            #bigM_mean = np.mean(bigM)\n",
    "            #bigM_std = np.std(bigM)\n",
    "            #bigM = (bigM - bigM_mean)/bigM_std\n",
    "        else:\n",
    "            bigM[i,:,:,0] = data_pad\n",
    "        \n",
    "    return bigM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(images, hints, masks):\n",
    "    bigM_base = make256(images, hints)\n",
    "    print(\"base shape\", bigM_base.shape)\n",
    "    bigM_mask = make256(masks)\n",
    "    print(\"mask shape\", bigM_mask.shape)\n",
    "    return bigM_base, bigM_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_split_indices(subjects, subjects_all):\n",
    "    idx = list(range(len(set(subjects))))\n",
    "    np.random.shuffle(idx)\n",
    "    train_subs = idx[:int(0.8*subjects.shape[0])]\n",
    "    test_subs = idx[int(0.8*subjects.shape[0]):int(0.9*subjects.shape[0])]\n",
    "    val_subs = idx[int(0.9*subjects.shape[0]):]\n",
    "    train = [i for i, val in enumerate(subjects_all) if val in subjects[train_subs]]\n",
    "    np.random.shuffle(train)\n",
    "    test = [i for i, val in enumerate(subjects_all) if val in subjects[test_subs]]\n",
    "    np.random.shuffle(test)\n",
    "    val = [i for i, val in enumerate(subjects_all) if val in subjects[val_subs]]\n",
    "    np.random.shuffle(val)\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_affine():\n",
    "    rotation = np.random.rand()*np.pi/45/2 * (np.random.binomial(1,0.5) * 2 - 1) # +- 4 degrees\n",
    "    shear = np.random.rand()*np.pi/45/2 * (np.random.binomial(1,0.5) * 2 - 1) # +- 4 degrees\n",
    "    translation = [t * (np.random.binomial(1,0.5) * 2 - 1) for t in np.random.rand(2) * 10] \n",
    "    scale = [1 + (t * (np.random.binomial(1,0.5) * 2 - 1)) for t in (np.random.rand(2) / 10)] \n",
    "    #print(\"r\", rotation, \"s\", shear, \"t\", translation, \"sc\", scale)\n",
    "    return AffineTransform(scale=scale, rotation=rotation, shear=shear, translation=translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiggle_image(data, truth):\n",
    "    xfm = get_random_affine()\n",
    "    return warp(data, xfm), warp(truth, xfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(x_arr, y_arr):\n",
    "    X = np.zeros(x_arr.shape)\n",
    "    Y = np.zeros(y_arr.shape)\n",
    "    for idx, img in enumerate(x_arr):\n",
    "        y_img = y_arr[idx,:,:,:]\n",
    "        new_x, new_y = wiggle_image(img, y_img)\n",
    "        X[idx, :,:,:] = new_x\n",
    "        Y[idx,:,:,:] = new_y\n",
    "    return x_arr, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_train_val(x_train, y_train, x_val, y_val, aug_num = 10):\n",
    "    \n",
    "    x_train_aug = x_train.copy()\n",
    "    y_train_aug = y_train.copy()\n",
    "\n",
    "    x_val_aug = x_val.copy()\n",
    "    y_val_aug = y_val.copy()\n",
    "\n",
    "\n",
    "    for i in range(aug_num):\n",
    "        x_train_a, y_train_a = augment_data(x_train, y_train)\n",
    "        x_val_a, y_val_a = augment_data(x_val, y_val)\n",
    "\n",
    "        x_train_aug = np.vstack((x_train_aug, x_train_a))\n",
    "        y_train_aug = np.vstack((y_train_aug, y_train_a))\n",
    "        x_val_aug = np.vstack((x_val_aug, x_val_a))\n",
    "        y_val_aug = np.vstack((y_val_aug, y_val_a))\n",
    "        print(x_train_aug.shape, x_val_aug.shape)\n",
    "        #break\n",
    "    return x_train_aug, y_train_aug, x_val_aug, y_val_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_hints(x_train_aug, x_val_aug):\n",
    "    # randomly remove the hint in some images\n",
    "    count = 0\n",
    "    for i in range(x_train_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.1):\n",
    "            count +=1\n",
    "            x_train_aug[i,:,:,1] = 0\n",
    "\n",
    "    print(count/x_train_aug.shape[0]*100, \"% removed\")\n",
    "\n",
    "    count = 0\n",
    "    for i in range(x_val_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.1):\n",
    "            count +=1\n",
    "            x_val_aug[i,:,:,1] = 0\n",
    "\n",
    "    print(count/x_val_aug.shape[0]*100, \"% removed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weaken_hints(x_train_aug, x_val_aug):\n",
    "    count = 0\n",
    "    for i in range(x_train_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.3):\n",
    "            count +=1\n",
    "            hint = x_train_aug[i,:,:,1]\n",
    "            x_train_aug[i,:,:,1], _ = wiggle_image(hint, hint)\n",
    "\n",
    "    print(count/x_train_aug.shape[0]*100, \"% wiggled hints\")\n",
    "\n",
    "    count = 0\n",
    "    for i in range(x_val_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.3):\n",
    "            count +=1\n",
    "            hint = x_val_aug[i,:,:,1]\n",
    "            x_val_aug[i,:,:,1], _ = wiggle_image(hint, hint)\n",
    "\n",
    "    print(count/x_val_aug.shape[0]*100, \"% wiggled hints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dilate_or_erode_image(img, do_dilate):\n",
    "    if do_dilate:\n",
    "        return dilation(img, disk(3))\n",
    "    else:\n",
    "        return erosion(img, disk(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dilate_erode_hints(x_train_aug, x_val_aug):\n",
    "    count = 0\n",
    "    for i in range(x_train_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.3):\n",
    "            count +=1\n",
    "            hint = x_train_aug[i,:,:,1]\n",
    "            x_train_aug[i,:,:,1] = dilate_or_erode_image(hint, np.random.binomial(1,0.5))\n",
    "\n",
    "    print(count/x_train_aug.shape[0]*100, \"% dilated or eroded hints\")\n",
    "\n",
    "    count = 0\n",
    "    for i in range(x_val_aug.shape[0]):\n",
    "        if np.random.binomial(1,0.3):\n",
    "            count +=1\n",
    "            hint = x_val_aug[i,:,:,1]\n",
    "            x_val_aug[i,:,:,1] = dilate_or_erode_image(hint, np.random.binomial(1,0.5))\n",
    "\n",
    "    print(count/x_val_aug.shape[0]*100, \"% dilated or eroded hints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_log_dir():\n",
    "    current_logs = sorted(glob(\"./log_try_????\"))\n",
    "    if len(current_logs) == 0:\n",
    "        return \"./log_try_0000\"\n",
    "    else:\n",
    "        max_num = int(current_logs[-1].split(\"_\")[-1])\n",
    "        return \"./log_try_%04d\" % (max_num + 1)\n",
    "    \n",
    "def get_new_checkpoint_dir():\n",
    "    current_logs = sorted(glob(\"./checkpoint_try_????\"))\n",
    "    if len(current_logs) == 0:\n",
    "        return \"./checkpoint_try_0000\"\n",
    "    else:\n",
    "        max_num = int(current_logs[-1].split(\"_\")[-1])\n",
    "        return \"./checkpoint_try_%04d\" % (max_num + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_all = []\n",
    "\n",
    "def run_everything(model_save_path):\n",
    "    \n",
    "    stats = {}\n",
    "    if not exists(model_save_path):\n",
    "        makedirs(model_save_path)\n",
    "    \n",
    "    # get data\n",
    "    images = sorted(glob(\"../tiles/*/base*.jpg\"))\n",
    "    hints = sorted(glob(\"../tiles/*/agg*.png\"))\n",
    "    masks =sorted(glob(\"../tiles/*/truth*.png\"))\n",
    "    assert(len(images) == len(masks))\n",
    "    assert(len(hints) == len(masks))\n",
    "    \n",
    "    subjects_all = [i.split(\"/\")[-2] for i in images]\n",
    "    subjects = np.asarray(sorted(list(set(subjects_all))))\n",
    "\n",
    "    bigM_base, bigM_mask = get_data(images, hints, masks)\n",
    "    \n",
    "    #splitting data\n",
    "    train, test, val = get_split_indices(subjects, subjects_all)\n",
    "    x_train = bigM_base[train, :]\n",
    "    y_train = bigM_mask[train, :]\n",
    "\n",
    "    x_test = bigM_base[test, :]\n",
    "    y_test = bigM_mask[test, :]\n",
    "\n",
    "    x_val = bigM_base[val, :]\n",
    "    y_val = bigM_mask[val, :]\n",
    "    \n",
    "    #augment data\n",
    "    x_train_aug, y_train_aug, x_val_aug, y_val_aug = augment_train_val(x_train, y_train, x_val, y_val, aug_num = 10)\n",
    "    remove_hints(x_train_aug, x_val_aug)\n",
    "    weaken_hints(x_train_aug, x_val_aug)\n",
    "    dilate_erode_hints(x_train_aug, x_val_aug)\n",
    "    \n",
    "    #save all our data:\n",
    "    np.savez(join(model_save_path, \"data.npz\"), {\"images\": images, \"hints\": hints, \"masks\": masks,\n",
    "                                                \"subjects_all\": subjects_all, \"subjects\": subjects, \n",
    "                                                \"bigM_base\": bigM_base, \"bigM_mask\": bigM_mask,\n",
    "                                                \"train_idx\": train, \"test_idx\": test, \"val_idx\": val,\n",
    "                                                \"x_train\": x_train, \"y_train\": y_train, \"x_val\": x_val,\n",
    "                                                \"y_val\": y_val, \"x_test\": x_test, \"y_test\": y_test,\n",
    "                                                \"x_train_aug\": x_train_aug, \"y_train_aug\": y_train_aug,\n",
    "                                                \"x_val_aug\": x_val_aug, \"y_val_aug\": y_val_aug})\n",
    "    \n",
    "    #run the model\n",
    "    model = get_model()\n",
    "    model.fit(x_train_aug, y_train_aug, batch_size=4, \n",
    "          epochs=20, verbose=1, validation_data=(x_val_aug, y_val_aug), \n",
    "          callbacks=[keras.callbacks.TensorBoard(log_dir=get_new_log_dir(), histogram_freq=0, \n",
    "                                                 batch_size=4, write_graph=True, \n",
    "                                                 write_grads=True, write_images=True, \n",
    "                                                 embeddings_freq=0, embeddings_layer_names=None, \n",
    "                                                 embeddings_metadata=None),\n",
    "                     keras.callbacks.ModelCheckpoint(get_new_checkpoint_dir(), monitor='val_dice', \n",
    "                                                     verbose=0, save_best_only=False, save_weights_only=False, \n",
    "                                                     mode='auto', period=1)\n",
    "                    ]\n",
    "    )\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    print(\"test score with hints\", score)\n",
    "    stats[\"score_with_hints\"] = score\n",
    "    \n",
    "    x_test_no_hint = x_test.copy()\n",
    "    x_test_no_hint[:,:,:,1] = 0\n",
    "    score_no_hint = model.evaluate(x_test_no_hint, y_test)\n",
    "    print(\"score w/ no hint\", score_no_hint)\n",
    "    stats[\"score w/ no hint\"] = score_no_hint\n",
    "    \n",
    "    x_test_no_brain = x_test.copy()\n",
    "    x_test_no_brain[:,:,:,0] = 0\n",
    "    score_no_brain = model.evaluate(x_test_no_brain, y_test)\n",
    "    print(\"score w/ no brain\", score_no_brain)\n",
    "    stats[\"score no brain\"] = score_no_brain\n",
    "    \n",
    "    model.save(\"{}/model.h5\".format(model_save_path))\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base shape (188, 256, 256, 2)\n",
      "mask shape (188, 256, 256, 1)\n",
      "(308, 256, 256, 2) (54, 256, 256, 2)\n",
      "(462, 256, 256, 2) (81, 256, 256, 2)\n",
      "(616, 256, 256, 2) (108, 256, 256, 2)\n",
      "(770, 256, 256, 2) (135, 256, 256, 2)\n",
      "(924, 256, 256, 2) (162, 256, 256, 2)\n",
      "(1078, 256, 256, 2) (189, 256, 256, 2)\n",
      "(1232, 256, 256, 2) (216, 256, 256, 2)\n",
      "(1386, 256, 256, 2) (243, 256, 256, 2)\n",
      "(1540, 256, 256, 2) (270, 256, 256, 2)\n",
      "(1694, 256, 256, 2) (297, 256, 256, 2)\n",
      "9.85832349468713 % removed\n",
      "9.764309764309765 % removed\n",
      "31.109799291617474 % wiggled hints\n",
      "25.589225589225588 % wiggled hints\n",
      "30.519480519480517 % dilated or eroded hints\n",
      "31.313131313131315 % dilated or eroded hints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshavan/software/keratin/keratin/networks.py:89: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "  return km.Model(input=inputs, outputs=outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1694 samples, validate on 297 samples\n",
      "Epoch 1/20\n",
      "1694/1694 [==============================] - 32s - loss: -0.6549 - dice: 0.6549 - val_loss: -0.6955 - val_dice: 0.6955\n",
      "Epoch 2/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.7663 - dice: 0.7663 - val_loss: -0.6941 - val_dice: 0.6941\n",
      "Epoch 3/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.7777 - dice: 0.7777 - val_loss: -0.7336 - val_dice: 0.7336\n",
      "Epoch 4/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.8435 - dice: 0.8435 - val_loss: -0.7835 - val_dice: 0.7835\n",
      "Epoch 5/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.8816 - dice: 0.8816 - val_loss: -0.7442 - val_dice: 0.7442\n",
      "Epoch 6/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9046 - dice: 0.9046 - val_loss: -0.8231 - val_dice: 0.8231\n",
      "Epoch 7/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9244 - dice: 0.9244 - val_loss: -0.8058 - val_dice: 0.8058\n",
      "Epoch 8/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9363 - dice: 0.9363 - val_loss: -0.8207 - val_dice: 0.8207\n",
      "Epoch 9/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9450 - dice: 0.9450 - val_loss: -0.8096 - val_dice: 0.8096\n",
      "Epoch 10/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9483 - dice: 0.9483 - val_loss: -0.8217 - val_dice: 0.8217\n",
      "Epoch 11/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9513 - dice: 0.9513 - val_loss: -0.8206 - val_dice: 0.8206\n",
      "Epoch 12/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9583 - dice: 0.9583 - val_loss: -0.7535 - val_dice: 0.7535\n",
      "Epoch 13/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9655 - dice: 0.9655 - val_loss: -0.7867 - val_dice: 0.7867\n",
      "Epoch 14/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9662 - dice: 0.9662 - val_loss: -0.7700 - val_dice: 0.7700\n",
      "Epoch 15/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9696 - dice: 0.9696 - val_loss: -0.8063 - val_dice: 0.8063\n",
      "Epoch 16/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9712 - dice: 0.9712 - val_loss: -0.8067 - val_dice: 0.8067\n",
      "Epoch 17/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9726 - dice: 0.9726 - val_loss: -0.7912 - val_dice: 0.7912\n",
      "Epoch 18/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9768 - dice: 0.9768 - val_loss: -0.7862 - val_dice: 0.7862\n",
      "Epoch 19/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9781 - dice: 0.9781 - val_loss: -0.8096 - val_dice: 0.8096\n",
      "Epoch 20/20\n",
      "1694/1694 [==============================] - 30s - loss: -0.9760 - dice: 0.9760 - val_loss: -0.7814 - val_dice: 0.7814\n",
      "7/7 [==============================] - 0s\n",
      "test score with hints [-0.71517479419708252, 0.71517473459243774]\n",
      "7/7 [==============================] - 0s\n",
      "score w/ no hint [-0.69441187381744385, 0.69441181421279907]\n",
      "7/7 [==============================] - 0s\n",
      "score w/ no brain [-0.00088176660938188434, 0.00088176660938188434]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    stats = run_everything(\"test_ak_%04d\" % i)\n",
    "    stats_all.append(stats)\n",
    "    save_json(\"model_stats.json\", stats)\n",
    "    cmds = [[\"git\", \"add\", \"model_stats.json\"],\n",
    "    [\"git\", \"commit\", \"-m\", '\"autocommit iteration %04d\"' % i],\n",
    "    [\"git\", \"push\", \"origin\", \"master\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_nohint_model.h5             keras_keratin_imgonly.ipynb  \u001b[0m\u001b[01;34mold\u001b[0m/\r\n",
      "getTiles.ipynb                   keras_keratin.ipynb          test_ak_0000.h5\r\n",
      "keras_keratin-Copy1.ipynb        kk_all.ipynb                 Untitled.ipynb\r\n",
      "keras_keratin-imgonly_aug.ipynb  medulina_data.ipynb\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
